# 帥石 3090 全部步驟

---

# Dataset 處理

---

nnUNet 的資料需要嚴格的結構，`Dataset666_Heart` ，`Dataset` 為必須，緊接著的 `666` 為一個 dataset 的編號，也可以取為 001。

這個資料集皆為官方提供的 dataset 檔案。

```json
data/
├── nnUNet_preprocessed/
├── nnUNet_raw/
│		├── Dataset666_Heart
│		├── dataset.json
│		├── imagesTr
│   │   ├── patient0001_0000.nii.gz
│   │   ├── patient0002_0000.nii.gz
│   │   ├── patient0003_0000.nii.gz
│   │   ├── ...
│		├── imagesTs
│   │   ├── patient0051_0000.nii.gz
│   │   ├── patient0052_0000.nii.gz
│   │   ├── patient0053_0000.nii.gz
│   │   ├── ...
│		└── labelsTr
│       ├── patient0001.nii.gz
│       ├── patient0002.nii.gz
│       ├── patient0003.nii.gz
│       ├── ...
└── nnUNet_results/
```

其中 `dataset.json` 的檔案如下：

```json
{
  "name": "Dataset666_Heart",
  "channel_names": { "0": "CT" },
  "labels": {
    "background": 0,
    "myocardium": 1,
    "aortic_valve_leaflet": 2,
    "calcification": 3
  },
  "file_ending": ".nii.gz",
  "numTraining": 50
} 
```

**詳細請見：**

[nnUNet/documentation/dataset_format.md at master · MIC-DKFZ/nnUNet](https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/dataset_format.md#dataset-folder-structure)

# 專案實作流程

## 創建資料夾

```bash
mkdir heart_final

cd heart_final
```

## 使用前段部份處理好的 `data`

附圖為目前應該要有的資料（imageTr, imageTs, labelsTr 中的檔案皆為前段部分的命名方式，並且為此次比賽提供的 dataset ）

![截圖 2025-11-23 晚上9.48.11.png](%E6%88%AA%E5%9C%96_2025-11-23_%E6%99%9A%E4%B8%8A9.48.11.png)

## 創建 Dockerfile

為了保證不會有環境上的干擾，我們使用了 docker 在裡面訓練。

```bash
cd ~/heart_final

touch Dockerfile
```

以下為我們的 `Dockerfile`

使用 `pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime` 

以及下載 python 套件 `nnunetv2`

```docker
FROM pytorch/pytorch:2.3.0-cuda12.1-cudnn8-runtime

# Install common tools
RUN apt-get update && apt-get install -y --no-install-recommends \
    git wget curl vim tmux build-essential && \
    rm -rf /var/lib/apt/lists/*

RUN pip install --no-cache-dir nnunetv2

# Set nnUNet v2 environment variables
ENV nnUNet_raw=/workspace/data/nnUNet_raw
ENV nnUNet_preprocessed=/workspace/data/nnUNet_preprocessed
ENV nnUNet_results=/workspace/data/nnUNet_results

WORKDIR /workspace
```

## 創建 .dockerignore

```bash
touch .dockerignore
```

```bash
# ===== nnU-Net 資料夾（非常大，必須忽略） =====
data/

# ===== 工具與中間產物 =====
tools/
__pycache__/
*.pyc
*.pyo
*.pyd

# ===== 日誌檔 =====
*.log

# ===== 不需要加入 image 的本機設定 =====
*.tmp
*.swp
*.swo

# ===== Git / VScode =====
.git/
.gitignore
.vscode/

# ===== 系統檔案 =====
.DS_Store
Thumbs.db
```

## 創建 image

```bash
docker build -t heart-final:latest .
```

## 創建 container

先下指令 ，看記憶體有多少

```bash
free -h
```

![截圖 2025-11-23 晚上10.10.55.png](%E6%88%AA%E5%9C%96_2025-11-23_%E6%99%9A%E4%B8%8A10.10.55.png)

修改 —shm-size ，設置為 total - 20

修改 -v 

```bash
docker run -it \
--gpus all \
--name heart-final-con \
-v /home/yayou/heart_final/data:/workspace/data \
--shm-size 105g \
heart-final:latest bash
```

### 先退出，在用 exec 進入

```bash
exit
```

### 進入 docker container

```bash
docker start 
```

```bash
docker exec -it heart-final-con bash
```

## 階段一：預處理

### 使用 tmux

```bash
tmux new -s preprocessed
```

### 查看 cpu 數量

```bash
nproc
```

將以下 -np 改為 cpu數量 - 4，

![截圖 2025-11-23 晚上10.17.35.png](%E6%88%AA%E5%9C%96_2025-11-23_%E6%99%9A%E4%B8%8A10.17.35.png)

以範例，cpu 數量為 28 顆，np 設為 24

創建 `preprocessed.txt` 

```bash
/data/logs/preprocessed.txt
```

運行指令

```bash
nnUNetv2_plan_and_preprocess \
-d 666 \
--verify_dataset_integrity \
-np 24 \
| tee /workspace/data/logs/preprocessed.txt
```

### tmux 參考

想在 tmux 視窗中啟用滑動

```bash
ctrl+b 
接著按下 [
```

退出滑動模式

```bash
q
```

想在 tmux 視窗中退出，但依然保留運行

```bash
ctrl+b
接著按下
d
```

確認 tmux

```bash
tmux ls
```

![截圖 2025-11-23 晚上10.30.20.png](%E6%88%AA%E5%9C%96_2025-11-23_%E6%99%9A%E4%B8%8A10.30.20.png)

---

## 階段二：訓練

```bash
tmux new -s 3d_lowres
```

### **退出記得要**

```bash
ctrl+b
接著按
d
```

### **第一部分：訓練 3d_lowres 五層交叉驗證**

### 如果有兩顆以上 GPU 可以加上 `CUDA_VISIBLE_DEVICES=1` , `-num_gpus 2` 

```bash
CUDA_VISIBLE_DEVICES=1 nnUNetv2_train 666 3d_lowres 0 -num_gpus 2 \
| tee /workspace/data/logs/train_3d_lowres_fold0.txt
```

沒有的話用以下指令就好（每一個 fold 訓練完再換下一個

```bash
nnUNetv2_train 666 3d_lowres 0 --npz \
| tee /workspace/data/logs/train_3d_lowres_fold0.txt
```

```bash
nnUNetv2_train 666 3d_lowres 1 --npz \
| tee /workspace/data/logs/train_3d_lowres_fold1.txt
```

```bash
nnUNetv2_train 666 3d_lowres 2 --npz \
| tee /workspace/data/logs/train_3d_lowres_fold2.txt
```

```bash
nnUNetv2_train 666 3d_lowres 3 --npz \
| tee /workspace/data/logs/train_3d_lowres_fold3.txt
```

```bash
nnUNetv2_train 666 3d_lowres 4 --npz \
| tee /workspace/data/logs/train_3d_lowres_fold4.txt
```

### **第二部分：訓練 3d_cascade_fullres 五層交叉驗證**

```bash
tmux new -s 3d_cascade_fullres
```

### **退出記得要**

```bash
ctrl+b
接著按
d
```

```bash
nnUNetv2_train 666 3d_cascade_fullres 0 --npz \
| tee /workspace/data/logs/train_3d_cascade_fullres_fold0.txt
```

```bash
nnUNetv2_train 666 3d_cascade_fullres 1 --npz \
| tee /workspace/data/logs/train_3d_cascade_fullres_fold1.txt
```

```bash
nnUNetv2_train 666 3d_cascade_fullres 2 --npz \
| tee /workspace/data/logs/train_3d_cascade_fullres_fold2.txt
```

```bash
nnUNetv2_train 666 3d_cascade_fullres 3 --npz \
| tee /workspace/data/logs/train_3d_cascade_fullres_fold3.txt
```

```bash
nnUNetv2_train 666 3d_cascade_fullres 4 --npz \
| tee /workspace/data/logs/train_3d_cascade_fullres_fold4.txt
```

## 斷掉的話

**檢查點 (Checkpoints)：** 這些指令會自動保存檢查點。如果訓練中斷（例如停電），只需在原指令後加上 `--c` 即可從上次中斷處繼續。

```bash
nnUNetv2_train 666 3d_cascade_fullres 4 --npz --c \
| tee /workspace/data/logs/train_3d_cascade_fullres_fold4.txt
```

## 第三部分：**訓練 3d_fullres**

```bash
tmux new -s 3d_fullres
```

```bash
nnUNetv2_train 666 3d_fullres 0 --npz \
| tee /workspace/data/logs/train_3d_fullres_fold0.txt
```

```bash
nnUNetv2_train 666 3d_fullres 1 --npz \
| tee /workspace/data/logs/train_3d_fullres_fold1.txt
```

```bash
nnUNetv2_train 666 3d_fullres 2 --npz \
| tee /workspace/data/logs/train_3d_fullres_fold2.txt
```

```bash
nnUNetv2_train 666 3d_fullres 3 --npz \
| tee /workspace/data/logs/train_3d_fullres_fold3.txt
```

```bash
nnUNetv2_train 666 3d_fullres 4 --npz \
| tee /workspace/data/logs/train_3d_fullres_fold3.txt
```

## 階段三：find best

```bash
tmux new -s find_best
```

### **退出記得要**

```bash
ctrl+b
接著按
d
```

```bash
nnUNetv2_find_best_configuration 666 -c 3d_lowres 3d_cascade_fullres 3d_fullres \
| tee /workspace/data/logs/find_best.txt
```

## 階段四：預測

根據 find best 會產生結果，查看 `inference_information.json` 的結果，他會告訴你最好的模型是哪個或是哪個組合，以我們後來做的 Mplan 結果為例。（此 Mplan 並不是本比賽最佳成績，這裏只是作為示範）

```json
{
    "all_results": {
        "ensemble___nnUNetTrainer__nnUNetResEncUNetMPlans__3d_cascade_fullres___nnUNetTrainer__nnUNetResEncUNetMPlans__3d_fullres___0_1_2_3_4": 0.5609250986979016,
        "ensemble___nnUNetTrainer__nnUNetResEncUNetMPlans__3d_lowres___nnUNetTrainer__nnUNetResEncUNetMPlans__3d_cascade_fullres___0_1_2_3_4": 0.5582162152051763,
        "ensemble___nnUNetTrainer__nnUNetResEncUNetMPlans__3d_lowres___nnUNetTrainer__nnUNetResEncUNetMPlans__3d_fullres___0_1_2_3_4": 0.5602527015944814,
        "nnUNetTrainer__nnUNetResEncUNetMPlans__3d_cascade_fullres": 0.5581944639063796,
        "nnUNetTrainer__nnUNetResEncUNetMPlans__3d_fullres": 0.5614019925536775,
        "nnUNetTrainer__nnUNetResEncUNetMPlans__3d_lowres": 0.553078590484884
    },
    "best_model_or_ensemble": {
        "postprocessing_file": "/workspace/data/nnUNet_results/Dataset666_Heart/nnUNetTrainer__nnUNetResEncUNetMPlans__3d_fullres/crossval_results_folds_0_1_2_3_4/postprocessing.pkl",
        "result_on_crossval_post_pp": 0.5614544817256686,
        "result_on_crossval_pre_pp": 0.5614019925536775,
        "selected_model_or_models": [
            {
                "configuration": "3d_fullres",
                "plans_identifier": "nnUNetResEncUNetMPlans",
                "trainer": "nnUNetTrainer"
            }
        ],
        "some_plans_file": "/workspace/data/nnUNet_results/Dataset666_Heart/nnUNetTrainer__nnUNetResEncUNetMPlans__3d_fullres/crossval_results_folds_0_1_2_3_4/plans.json"
    },
    "considered_models": [
        {
            "configuration": "3d_lowres",
            "plans": "nnUNetResEncUNetMPlans",
            "trainer": "nnUNetTrainer"
        },
        {
            "configuration": "3d_cascade_fullres",
            "plans": "nnUNetResEncUNetMPlans",
            "trainer": "nnUNetTrainer"
        },
        {
            "configuration": "3d_fullres",
            "plans": "nnUNetResEncUNetMPlans",
            "trainer": "nnUNetTrainer"
        }
    ],
    "dataset_name_or_id": "Dataset666_Heart",
    "ensembling_allowed": true,
    "folds": [
        0,
        1,
        2,
        3,
        4
    ]
}
```

### 結果一，單一模型獲勝：預測指令

**注意 -c 選擇正確模型**

**注意 -o 選擇輸出資料夾**

```bash
nnUNetv2_predict \
-d Dataset666_Heart \
-c 3d_fullres \
-i data/nnUNet_raw/Dataset666_Heart/imagesTs \
-o data/nnUNet_results/Dataset666_Heart/3D_fullres_prediction \
-f 0 1 2 3 4 \
| tee /workspace/data/logs/predict_from_3d_fullres.txt
```

### 結果二：集成模型獲勝 (此為假設，我們訓練的成果都是 **3D Fullres 單一模型為最高分**）

如果 `find_best_configuration` 的結果判定 **「3D Fullres + 3D Cascade Fullres」的集成（Ensemble）組合獲勝。**

### 關鍵差異：`-save_probabilities`

要進行集成，不能只輸出「分割圖片 (Mask)」，必須輸出「**機率圖 (Probabilities)**」。因此，在預測指令中必須加上 **`--save_probabilities`** 參數。

### 步驟 1：產出第一個模型的預測 (3d_fullres)

請將結果存在一個專屬資料夾（例如 `pred_fullres`）。

```bash
nnUNetv2_predict \
-d Dataset666_Heart \
-i data/nnUNet_raw/Dataset666_Heart/imagesTs \
-o data/nnUNet_results/Dataset666_Heart/3D_fullres_prediction \
-f 0 1 2 3 4 \
-c 3d_fullres \
--save_probabilities
```

### 步驟 2：產出第二個模型的預測 (3d_cascade_fullres)

請將結果存在另一個專屬資料夾（例如 `pred_cascade`）。

```bash
nnUNetv2_predict \
-d Dataset666_Heart \
-i data/nnUNet_raw/Dataset666_Heart/imagesTs \
-o data/nnUNet_results/Dataset666_Heart/3D_cascade_fullres_prediction \
-f 0 1 2 3 4 \
-c 3d_cascade_fullres \
--save_probabilities
```

---

### 步驟 3：執行集成 (Ensemble)

使用 `nnUNetv2_ensemble` 指令將它們合併，並生成出最後的結果。

**注意 np 可改**

```bash
nnUNetv2_ensemble \
-i data/nnUNet_results/Dataset666_Heart/3D_fullres_prediction data/nnUNet_results/Dataset666_Heart/3D_cascade_fullres_prediction \
-o data/nnUNet_results/Dataset666_Heart/ensemble_result \
-np 8
```

### 步驟 4：執行後處理 (Post-processing)

最後，對集成後的結果應用 `find_best` 建議的後處理規則。

```bash
nnUNetv2_apply_postprocessing \
-i data/nnUNet_results/Dataset666_Heart/ensemble_result \
-o data/nnUNet_results/Dataset666_Heart/ensemble_result_post \
-pp_pkl_file [路徑請參考 find_best 的輸出] \
-plans_json [路徑請參考 find_best 的輸出] \
-np 8
```